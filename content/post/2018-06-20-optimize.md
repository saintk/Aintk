---
title: "非线性最小二乘"
tags: ["VIO","SLAM" ]
date: "2018-06-20"
---
高博的SLAM十四讲写的很好，但有些地方可能大家会有点疑问，或者说是不够详尽。
这里介绍细节的非线性最小二乘的方法。
<!--more-->

## 1. 最小二乘问题
最简单的最小二乘问题：  
$$ \underset{x}{min}\frac{1}{2}||f(x)||_{2}^{2} $$
自变量 $x\epsilon\mathbb{R}^{n}$ ，f是任意非线性函数，设它为m维:$f(x)\epsilon\mathbb{R}^{m}$。  
如果f的形式很简单，问题可能可以用解析形式求解，即令目标函数的导数为零，进而求得x的最优值。但实际应用中并不方便使用这种方法，更多的是使用迭代逼近的方法取找到导数为0的点。

### 1.1 梯度下降法
将目标函数 $||f(x)||^{2}$在x处进行taylor展开：
$$||f(x+\Delta{x})||^{2} \thickapprox ||f(x)||^{2} + J(x)\Delta{x} + \frac{1}{2}\Delta{x}^{T}H\Delta{x}$$  
J是目标函数$||f(x)||^{2}$关于x的导数，即jacobian矩阵，H为Hssian矩阵。  
如果仅保留一阶项，整理有：
$$||f(x)||^{2} - ||f(x+\Delta{x})||^{2} =  -J(x)\Delta{x}$$  
在$\Delta{x}$是下降的方向的前提下，即$J(x)\Delta{x}<0$，就可以把右边看作是目标函数从x到$x+\Delta{x}$下降的量。

进一步，$\Delta{x}$取多少才能使下降量尽可能大？
首先引入一个步长参数$\lambda$来控制学习率，而限定$\Delta{x}$为单位长度，则显然，当取$\lambda>0$，$\Delta{x}$与-J(x)同向时，右式最大。

即结论是函数沿负梯度方向下降最快，即: $\Delta{x^{*}} = -J^{T}(x)$ ，而具体下降的多少，则有步长$\lambda$来确定。

---

## 1.2 牛顿法

--- 未完待续 ---