<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Aintk</title>
    <link>https://www.aintk.xyz/</link>
    <description>Recent content on Aintk</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>© This post is licensed under a Creative Commons Attribution-NonCommercial 4.0 International License，please give source if you wish to quote or reproduce.</copyright>
    <lastBuildDate>Wed, 30 May 2018 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="https://www.aintk.xyz/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Home</title>
      <link>https://www.aintk.xyz/home/</link>
      <pubDate>Wed, 30 May 2018 00:00:00 +0000</pubDate>
      
      <guid>https://www.aintk.xyz/home/</guid>
      <description>王兆圣的个人主页。 目前在闵行男子职业技术学院学习，后续会将学习过程中的点滴知识记录在这里。
 I&amp;rsquo;ve got you in my sights.</description>
    </item>
    
    <item>
      <title>Links</title>
      <link>https://www.aintk.xyz/links/</link>
      <pubDate>Wed, 30 May 2018 00:00:00 +0000</pubDate>
      
      <guid>https://www.aintk.xyz/links/</guid>
      <description></description>
    </item>
    
    <item>
      <title>About</title>
      <link>https://www.aintk.xyz/about/</link>
      <pubDate>Wed, 30 May 2018 00:00:00 +0000</pubDate>
      
      <guid>https://www.aintk.xyz/about/</guid>
      <description>社会你王哥 以后再补</description>
    </item>
    
    <item>
      <title>使用ArUco定位</title>
      <link>https://www.aintk.xyz/post/aruco/</link>
      <pubDate>Sun, 10 Jun 2018 00:00:00 +0000</pubDate>
      
      <guid>https://www.aintk.xyz/post/aruco/</guid>
      <description>1. 配置安装 ArUco库下载:
https://sourceforge.net/projects/aruco/files/
这里我使用的是3.0.10版本,按照readme安装。(make install)
编译安装MarkerMapper:
https://sourceforge.net/p/markermapper/activity/?page=0&amp;amp;limit=100#5addf1323241d20a481f2a02
这里我使用的是1.0.12版本，按照readme安装。(make install)
2. 采集数据并构图 参照Marker_Mapper中的Readme文件，执行一下命令:
./utils/mapper_from_video video.avi camera.yml 0.1 -out markerset -d dict  其中为拍摄有marker的视频，camera.yml为相机内参，0.1为相关的tag大小， video.avi:拍摄有marker的视频.
camera.yml:相机内参.
0.1：为marker的大小，按实际情况给定.
-o map: 生成的文件. -d : 制定使用的marker字典，按照所使用的marker指定，有ARUCO_MIP_16h3 ARUCO_MIP_25h7 ARUCO_MIP_36h12等.
如图所示: 我们所用的dict为ARUCO_MIP_36h12 最后我们将得到markerset.yml以及相应的pcd文件,如果结果markerset的结果不好请检查相机标定参数和marker的参数.
3. 使用api获取当前位置 通过调用aruco的相关接口，来获取当前位置. 有四个需要定义的接口:
 CameraParameters TheCameraParameters; // 相机内参 MarkerMap TheMarkerMapConfig; // 地图参数 MarkerDetector TheMarkerDetector; // Marker检测 MarkerMapPoseTracker TheMSPoseTracker; // 位置跟踪接口  具体可以使用也很简单，可以参照官网的接口.
对每一帧图像可以通过如下操作获得相机位姿.
vector&amp;lt;aruco::Marker&amp;gt; detectedMarkers = TheMarkerDetector.detect(TheInputImage); for (auto idx:TheMarkerMapConfig.getIndices(detectedMarkers)) detectedMarkers[idx].draw(TheInputImageCopy, Scalar(0, 0, 255), 2); if (TheMSPoseTracker.</description>
    </item>
    
    <item>
      <title>使用evo评估VINS-MONO</title>
      <link>https://www.aintk.xyz/post/evo%E5%B7%A5%E5%85%B7%E7%9A%84%E4%BD%BF%E7%94%A8/</link>
      <pubDate>Thu, 07 Jun 2018 00:00:00 +0000</pubDate>
      
      <guid>https://www.aintk.xyz/post/evo%E5%B7%A5%E5%85%B7%E7%9A%84%E4%BD%BF%E7%94%A8/</guid>
      <description>EVO工具用于评估SLAM算法在现有数据集上的效果。
源码在 https://github.com/MichaelGrupp/evo
目前支持 TUM KITTI Euroc 等格式
evo工具提供了3种误差评估方式:
 evo_ape -absoulte pose error
 evo_rpe -relative pose error
 evo_rpe -for-each -sub-sequence-wise averaged pose error  4种工具：
 evo_traj - tool for analyzing, plotting or exporting one or more trajectories evo_res - tool for comparing one or multiple result files from evo_ape or evo_rpe evo_fig - (experimental) tool for re-opening serialized plots (saved with &amp;ndash;serialize_plot) evo_config - tool for global settings and config file manipulation  1.</description>
    </item>
    
    <item>
      <title>vicon-imu标定系统</title>
      <link>https://www.aintk.xyz/post/vicon-imu%E6%A0%87%E5%AE%9A%E7%B3%BB%E7%BB%9F%E4%B8%80/</link>
      <pubDate>Tue, 05 Jun 2018 00:00:00 +0000</pubDate>
      
      <guid>https://www.aintk.xyz/post/vicon-imu%E6%A0%87%E5%AE%9A%E7%B3%BB%E7%BB%9F%E4%B8%80/</guid>
      <description> 1. 基本理念 一般情况对imu的简单建模
$$ X_{m}=X_{t}+X_{b}+X_{n} $$
其中，X代表acc和gyro，下标m:测量量，t:真值， b: 零偏， n: 白噪声
零偏Xb通常为一个常量，但会随时间,温度,湿度的改变而改变，具有随机游走性质，其导数服从零均值高斯分布。 因为这个特性，过一段时间imu内参就需要重新标定一次，标定方法有很多，可以使用一些工具，如kalibr, imu_tk等。
然而在常见vio算法中，在估计位置，速度，姿态的同时，也会同时估算出imu的内参，但想去评估它的准确度是有难度的，每次采数据之前都做一遍标定也比较麻烦。 因此使用高精度的动作捕获系统vicon来估计这个值，无需多余的工作量。
2. 理论推导 </description>
    </item>
    
    <item>
      <title>有点心烦</title>
      <link>https://www.aintk.xyz/post/%E6%9C%89%E7%82%B9%E5%BF%83%E7%83%A6/</link>
      <pubDate>Tue, 05 Jun 2018 00:00:00 +0000</pubDate>
      
      <guid>https://www.aintk.xyz/post/%E6%9C%89%E7%82%B9%E5%BF%83%E7%83%A6/</guid>
      <description>BUG 调不出啊，狠难受啊！！！ 有点想放弃了！！！
感觉可以推倒重新来过了。。。</description>
    </item>
    
  </channel>
</rss>